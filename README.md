# awesome-Inspection_robot_with_LLMs
 Inspection robot driven by multimodal large language model-related learning resource library.

 Any additions, corrections, or concerns please submit an issue. For additions to the list, please provide the relevant information. Thank you!

 (Inspired by https://github.com/willxxy/awesome-mmps/) 

***

## Table of Contents

- [Publications and Preprints](#publications-and-preprints)
  - 3D Scene Understanding
  - Autonomous Navigation Based on Large Language Models
  - SLAM
  - Intelligent Dialogue and Task Collaboration
  - Automated Defect Identification and Diagnosis
  - Knowledge-Driven Fault Prediction and Maintenance Recommendations
  - Learning-Based Autonomous Systems and Feedback Mechanisms
  - Cloud and Edge Collaborative Computing
- [Datasets](#datasets)

- [Laboratories](#laboratories)

- [Citation](#citation)


## Publications-and-Preprints

### 3D Scene Understanding
- [Comparing Recognition Performance and Robustness of Multimodal Deep Learning Models for Multimodal Emotion Recognition](https://ieeexplore.ieee.org/abstract/document/9395500), IEEE TCDS 2021; [EEG, Eye Movement, Peripheral Physiological Signals, ECG]

### Autonomous Navigation Based on Large Language Models
- [Multimodal Representation Learning of Cardiovascular Magnetic Resonance Imaging](https://arxiv.org/pdf/2304.07675.pdf), ICML Workshop on Machine Learning for Multimodal Healthcare Data 2023; [CMR, Language]

### Multimodal Semantic SLAM


### Intelligent Dialogue and Task Collaboration


### Automated Defect Identification and Diagnosis


### Knowledge-Driven Fault Prediction and Maintenance Recommendations


### Real-Time Voice and Visual Command Execution


### Learning-Based Autonomous Systems and Feedback Mechanisms


### Cloud and Edge Collaborative Computing


### Energy Management Optimization for Multimodal Large Language Models


## Datasets
- [SEED](https://bcmi.sjtu.edu.cn/home/seed/seed.html); [EEG, Eye Movement, Video]
- [SEED-IV](https://bcmi.sjtu.edu.cn/home/seed/seed-iv.html); [EEG, Eye Movement, Video]
- [SEED-VIG](https://bcmi.sjtu.edu.cn/home/seed/seed-vig.html); [EEG, EOG]
- [SEED-V](https://bcmi.sjtu.edu.cn/home/seed/seed-v.html); [EEG, Eye Movement, Video]
- [SEED-GER](https://bcmi.sjtu.edu.cn/home/seed/seed-GER.html); [EEG, Eye Movement, Video]
- [SEED-FRA](https://bcmi.sjtu.edu.cn/home/seed/seed-FRA.html); [EEG, Eye Movement, Video]
- [ZuCo 2.0](https://osf.io/2urht/); [EEG, Language, Eye Movement]


## Laboratories
- [Neural Interfacing Lab @ Maastricht University](https://neuralinterfacinglab.github.io/)

## Citation
If you found this repository helpful in your research, please cite the following:

```
@software{Kang_Inspection_robot_of_2024,
author = {Jiaju Kang},
month = Sept,
title = {{Inspection robot driven by multimodal large language model-related learning resource library}},
url = {https://github.com/kangjiaju/awesome-Inspection_robot_with_LLMs},
version = {1.0.0},
year = {2024}
}
```
